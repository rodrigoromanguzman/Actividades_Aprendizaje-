{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigoromanguzman/Actividades_Aprendizaje-/blob/main/semana8/module5_python_for_data_science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Rodrigo Ildefonso Roman Guzman|A01794225|María de la Paz Rico Fernández|Semana 8 (Noviembre 6 2022)</h1>"
      ],
      "metadata": {
        "id": "uP1ejkoVpvvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Data Analysis with Python <b>Module 5</b><h2/>"
      ],
      "metadata": {
        "id": "Lr3KxiGaqHlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Model Evaluation and Refinement</h3>\n",
        "<p>Model evaluation tells how our model performs in the real world. The difference model evaluation has against smaple evaluation is that the former tells how well the model fits the data used in the train set and model evaluation is an indicator og how well the model does in test data.</p>"
      ],
      "metadata": {
        "id": "JCvmHS-7B158"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Linear Regression</h3>\n",
        "<p>Refers to one independent variable to make a prediction</p>\n",
        "$$\n",
        "Y: Response \\ Variable\\\\\\\\\\\\\\\\\\\\\n",
        "X: Predictor \\ Variables\n",
        "$$\n",
        "<h4>Linear function</h4>\n",
        "$$\n",
        "Yhat = a + b  X\n",
        "$$\n",
        "<p>Where <i>a</i> is the intercept and <i>b</i> is the coeficient or slope of the linear function</p>"
      ],
      "metadata": {
        "id": "mzaWm3wzCTQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of linear regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "#Download the data set\n",
        "path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/module_5_auto.csv'\n",
        "df = pd.read_csv(path)\n"
      ],
      "metadata": {
        "id": "Y-8rDOvJxvcB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
        "    width = 12\n",
        "    height = 10\n",
        "    plt.figure(figsize=(width, height))\n",
        "\n",
        "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
        "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
        "\n",
        "    plt.title(Title)\n",
        "    plt.xlabel('Price (in dollars)')\n",
        "    plt.ylabel('Proportion of Cars')\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    \n",
        "def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n",
        "    width = 12\n",
        "    height = 10\n",
        "    plt.figure(figsize=(width, height))\n",
        "    \n",
        "    \n",
        "    #training data \n",
        "    #testing data \n",
        "    # lr:  linear regression object \n",
        "    #poly_transform:  polynomial transformation object \n",
        " \n",
        "    xmax=max([xtrain.values.max(), xtest.values.max()])\n",
        "\n",
        "    xmin=min([xtrain.values.min(), xtest.values.min()])\n",
        "\n",
        "    x=np.arange(xmin, xmax, 0.1)\n",
        "\n",
        "\n",
        "    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n",
        "    plt.plot(xtest, y_test, 'go', label='Test Data')\n",
        "    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')\n",
        "    plt.ylim([-10000, 60000])\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "1ijRg4MhEWsP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Training and Testing</h2>\n",
        "\n",
        "<p>An important step in testing your model is to split your data into training and testing data. We will place the target data <b>price</b> in a separate dataframe <b>y_data</b>:</p>"
      ],
      "metadata": {
        "id": "W1LctP-Lsc5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_data = df['price']\n",
        "x_data=df.drop('price',axis=1)"
      ],
      "metadata": {
        "id": "irvYtKUJI1iU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>train_test_split allows us to randomly split the data into training and testing sets</p>"
      ],
      "metadata": {
        "id": "UkBU4qAgwrN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#we choose the testing data to be 10% of the total amount of data available\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)\n",
        "\n",
        "\n",
        "print(\"number of test samples :\", x_test.shape[0])\n",
        "print(\"number of training samples:\",x_train.shape[0])\n"
      ],
      "metadata": {
        "id": "UoF4e06RwxRj",
        "outputId": "8bc510e3-97aa-4b3e-92a2-bf35d9cc1427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of test samples : 21\n",
            "number of training samples: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Lets try this out with our linear regression model</p>"
      ],
      "metadata": {
        "id": "YH--3E_DvWlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lre=LinearRegression()\n",
        "lre.fit(x_train[['horsepower']], y_train)\n",
        "print('Score for test',lre.score(x_test[['horsepower']], y_test))\n",
        "print('Score for train',lre.score(x_train[['horsepower']], y_train))"
      ],
      "metadata": {
        "id": "riLzrBYXwbb1",
        "outputId": "17ce2acc-10d0-4de8-f45e-917a1acd8937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for test 0.36358755750788263\n",
            "Score for train 0.6619724197515104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Given that we trained our model with a larger amount of data, the error is decreased for the train model. And thus, the R^2 is larger.</p>"
      ],
      "metadata": {
        "id": "muFho3VTwq4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Using a 40% of the data for testing we get the following</p>"
      ],
      "metadata": {
        "id": "-cZdtzmYx6ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.40, random_state=1)\n",
        "lre=LinearRegression()\n",
        "lre.fit(x_train[['horsepower']], y_train)\n",
        "\n",
        "#we get balanced values\n",
        "print('Score for test',lre.score(x_test[['horsepower']], y_test))\n",
        "print('Score for train',lre.score(x_train[['horsepower']], y_train))"
      ],
      "metadata": {
        "id": "bcGp1qolx8uL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d1a836-6776-438e-e7a0-5f4ef27ed1de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for test 0.6111827529454426\n",
            "Score for train 0.6755325771980134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Cross Validation</h2>\n",
        "\n",
        "<p>Allows us to compare different machine learning methods and get a sense of how well they will perform in practive.</p>\n"
      ],
      "metadata": {
        "id": "Kl_lbpz7yBJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "#cv determines the number of folds (number of fraction we will split our data into)\n",
        "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)\n",
        "print('We get a score for each fold')\n",
        "print(Rcross)\n",
        "#We can get the average of these scores\n",
        "print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
      ],
      "metadata": {
        "id": "8au4T6WFPgwO",
        "outputId": "04c16480-d6a2-4de1-8e0f-de4e2a4305e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We get a score for each fold\n",
            "[0.7746232  0.51716687 0.74785353 0.04839605]\n",
            "We can get the average of these scores\n",
            "The mean of the folds are 0.522009915042119 and the standard deviation is 0.291183944475603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=2)\n",
        "print('These are the results for two folds')\n",
        "print(Rcross)\n",
        "#We can get the average of these scores\n",
        "print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
      ],
      "metadata": {
        "id": "o7gGcJv4PxLS",
        "outputId": "167e42ec-e160-4b24-fb40-5bf1b16ede59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are the results for two folds\n",
            "[0.59015621 0.44319613]\n",
            "The mean of the folds are 0.5166761697127429 and the standard deviation is 0.07348004195771385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Overfitting and Underfitting</h3>\n",
        "<p>Overfitting happens when the model is too flexible and fits the noise rather than the function</p>\n",
        "<p>Underfitting happens when the model is not flexible enough and does not account for the different cases</p>"
      ],
      "metadata": {
        "id": "NIKVtjTFQBep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)\n",
        "#prediction using train\n",
        "yhat_train = lr.predict(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
        "yhat_train[0:5]"
      ],
      "metadata": {
        "id": "Ebg2bLWA9kPq",
        "outputId": "c476f089-e793-44eb-e02f-48830782567f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26091.37901214,  7954.34606626, 26091.37901214, 19557.5951667 ,\n",
              "        5822.61408773])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction using test\n",
        "yhat_test = lr.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
        "yhat_test[0:5]"
      ],
      "metadata": {
        "id": "q1Qc3lwmQTMr",
        "outputId": "bffcc5b8-3111-4866-d373-d0d94c6bd7af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of linear regression:  (201, 4)\n",
            "Shape of polynomial regression:  (201, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Aqui me quede</h2>\n",
        "<p>Simplifies the process of preparing our data</p>\n"
      ],
      "metadata": {
        "id": "e3el_2Jb-CHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        " #First we create the pipeline\n",
        "Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]\n",
        "\n",
        "#Input the pipeline to the Pipe function\n",
        "\n",
        "pipe=Pipeline(Input)\n",
        "pipe\n",
        "\n",
        "#Continue the process of fitting and predicting\n",
        "Z = Z.astype(float)\n",
        "pipe.fit(Z,y)\n",
        "ypipe=pipe.predict(Z)\n",
        "ypipe[0:4]"
      ],
      "metadata": {
        "id": "ZEmAUMFc-FdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc88e132-c568-4719-9f43-bf3babbabbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fwd    118\n",
              "rwd     75\n",
              "4wd      8\n",
              "Name: drive-wheels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>How to determine if a model is a good fit??</h2>\n",
        "<p>\n",
        "<ul>\n",
        "    <li><i>What is a good R-squared value?</i></li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>When comparing models, <b>the model with the higher R-squared value is a better fit (close to 1)</b> for the data.\n",
        "<ul>\n",
        "    <li><i>What is a good MSE?</i></li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>When comparing models, <b>the model with the smallest MSE value is a better fit</b> for the data.</p>\n",
        "\n",
        "<h4>Let's take a look at the values for the different models.</h4>\n",
        "<p>Simple Linear Regression: Using Highway-mpg as a Predictor Variable of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.49659118843391759</li>\n",
        "    <li>MSE: 3.16 x10^7</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>Multiple Linear Regression: Using Horsepower, Curb-weight, Engine-size, and Highway-mpg as Predictor Variables of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.80896354913783497</li>\n",
        "    <li>MSE: 1.2 x10^7</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>Polynomial Fit: Using Highway-mpg as a Predictor Variable of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.6741946663906514</li>\n",
        "    <li>MSE: 2.05 x 10^7</li>\n",
        "</ul>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "cUyRgMKLU2oB"
      }
    }
  ]
}